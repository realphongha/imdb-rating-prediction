{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive H is Work & Project\n",
      " Volume Serial Number is 7895-AE27\n",
      "\n",
      " Directory of H:\\HUST\\20201\\DataScience_IT4930\\GitRepo\\imdb-rating-prediction\n",
      "\n",
      "01/04/2021  04:19 PM    <DIR>          .\n",
      "01/04/2021  04:19 PM    <DIR>          ..\n",
      "01/02/2021  08:58 PM                30 .gitignore\n",
      "01/02/2021  08:58 PM    <DIR>          .idea\n",
      "01/04/2021  04:19 PM    <DIR>          .ipynb_checkpoints\n",
      "01/02/2021  08:58 PM    <DIR>          crawler\n",
      "01/02/2021  08:58 PM               683 evaluate.py\n",
      "01/02/2021  08:58 PM             5,125 example.json\n",
      "01/02/2021  09:07 PM         3,570,932 imdb_rating_analysis.ipynb\n",
      "01/02/2021  08:59 PM             2,052 Jupyter Notebook (Anaconda3).lnk\n",
      "01/02/2021  08:58 PM             9,711 models.py\n",
      "01/02/2021  08:58 PM            68,707 prediction.txt\n",
      "01/02/2021  08:58 PM             9,582 preprocess.py\n",
      "01/02/2021  08:58 PM               181 README.md\n",
      "01/04/2021  04:18 PM                 0 run.ipynb\n",
      "01/02/2021  08:58 PM             3,184 run.py\n",
      "01/04/2021  04:19 PM               555 run2.ipynb\n",
      "01/02/2021  08:58 PM    <DIR>          __pycache__\n",
      "              12 File(s)      3,670,742 bytes\n",
      "               6 Dir(s)  61,012,217,856 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\HUST\\20201\\DataScience_IT4930\\GitRepo\\imdb-rating-prediction\\crawler\n"
     ]
    }
   ],
   "source": [
    "%cd crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (19.1.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (0.1.1)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (20.3.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (4.7.1)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.0.3)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.22.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (2.9.2)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (4.5.1)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=16.2.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (20.0.1)\n",
      "Requirement already satisfied: PyHamcrest!=1.10.0,>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (2.0.2)\n",
      "Requirement already satisfied: incremental>=16.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (17.5.0)\n",
      "Requirement already satisfied: Automat>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (19.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (47.3.1.post20200622)\n",
      "Requirement already satisfied: pyasn1 in c:\\programdata\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\programdata\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.7)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEXT PAGE: /search/title/?title_type=feature&countries=us&start=51\n",
      "NEXT PAGE: /search/title/?title_type=feature&countries=us&start=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-04 17:17:02 [scrapy.utils.log] INFO: Scrapy 2.4.0 started (bot: imdb)\n",
      "2021-01-04 17:17:02 [scrapy.utils.log] INFO: Versions: lxml 4.5.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 2.9.2, Platform Windows-10-10.0.19041-SP0\n",
      "2021-01-04 17:17:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2021-01-04 17:17:02 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'imdb',\n",
      " 'CLOSESPIDER_PAGECOUNT': 15,\n",
      " 'NEWSPIDER_MODULE': 'imdb.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['imdb.spiders']}\n",
      "2021-01-04 17:17:02 [scrapy.extensions.telnet] INFO: Telnet Password: 37c5fec05572a1c4\n",
      "2021-01-04 17:17:02 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.closespider.CloseSpider',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-01-04 17:17:03 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-01-04 17:17:03 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-01-04 17:17:03 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "['imdb.pipelines.MoviePipeline']\n",
      "2021-01-04 17:17:03 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-01-04 17:17:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-01-04 17:17:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-01-04 17:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/robots.txt> (referer: None)\n",
      "2021-01-04 17:17:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/search/title/?title_type=feature&countries=us> (referer: None)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0110527/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/search/title/?title_type=feature&countries=us&start=51> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt6878306/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt1067106/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0104940/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt7126948/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10310140/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt9866072/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10618286/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0094898/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0369436/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0304669/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10016180/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:10 [scrapy.core.engine] INFO: Closing spider (closespider_pagecount)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10600398/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10362466/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0087363/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0241527/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0110527/fullcredits> (referer: https://www.imdb.com/title/tt0110527/)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt5363618/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us&start=51)\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt4566758/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt0110527/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0104940/fullcredits> (referer: https://www.imdb.com/title/tt0104940/)\n",
      "2021-01-04 17:17:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt0104940/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0094898/fullcredits> (referer: https://www.imdb.com/title/tt0094898/)\n",
      "2021-01-04 17:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt9866072/fullcredits> (referer: https://www.imdb.com/title/tt9866072/)\n",
      "2021-01-04 17:17:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt0094898/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt6878306/fullcredits> (referer: https://www.imdb.com/title/tt6878306/)\n",
      "2021-01-04 17:17:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt9866072/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt6878306/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt1067106/fullcredits> (referer: https://www.imdb.com/title/tt1067106/)\n",
      "2021-01-04 17:17:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt1067106/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt10310140/fullcredits> (referer: https://www.imdb.com/title/tt10310140/)\n",
      "2021-01-04 17:17:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt0457939/> (referer: https://www.imdb.com/search/title/?title_type=feature&countries=us)\n",
      "2021-01-04 17:17:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt10310140/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/title/tt7126948/fullcredits> (referer: https://www.imdb.com/title/tt7126948/)\n",
      "2021-01-04 17:17:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.imdb.com/title/tt7126948/fullcredits>\n",
      "\n",
      "None\n",
      "2021-01-04 17:17:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 15909,\n",
      " 'downloader/request_count': 30,\n",
      " 'downloader/request_method_count/GET': 30,\n",
      " 'downloader/response_bytes': 7393223,\n",
      " 'downloader/response_count': 30,\n",
      " 'downloader/response_status_count/200': 30,\n",
      " 'elapsed_time_seconds': 10.928028,\n",
      " 'finish_reason': 'closespider_pagecount',\n",
      " 'finish_time': datetime.datetime(2021, 1, 4, 10, 17, 13, 955311),\n",
      " 'item_scraped_count': 8,\n",
      " 'log_count/DEBUG': 38,\n",
      " 'log_count/INFO': 10,\n",
      " 'request_depth_max': 3,\n",
      " 'response_received_count': 30,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 29,\n",
      " 'scheduler/dequeued/memory': 29,\n",
      " 'scheduler/enqueued': 121,\n",
      " 'scheduler/enqueued/memory': 121,\n",
      " 'start_time': datetime.datetime(2021, 1, 4, 10, 17, 3, 27283)}\n",
      "2021-01-04 17:17:13 [scrapy.core.engine] INFO: Spider closed (closespider_pagecount)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
